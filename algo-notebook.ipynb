{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from skimage.io import imread, imshow\n",
    "from skimage.feature import hog\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.transform import resize\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA_DIR contains \"training\"\n",
    "DATA_DIR = os.environ.get('DATA_DIR', '')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Preprocessing\n",
    "\n",
    "Given the image data, we first want all images to be of the same dimension. Also, since our dataset is small, we will reduce the size to 64x64 pixels and convert them to grayscale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dataset(data_dir):\n",
    "    categories = ['good', 'flare']\n",
    "    X = []\n",
    "    Y = []\n",
    "    for i, category in enumerate(categories):\n",
    "        for img in glob(data_dir+'training/'+category+'/*'):\n",
    "            raw_image = rgb2gray(imread(img))\n",
    "            X.append(resize(raw_image, (64,64)))\n",
    "            Y.append(i)\n",
    "            \n",
    "    return np.array(X),np.array(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = read_dataset(DATA_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Feature extraction and selection\n",
    "\n",
    "Now, we would like to extract features from the images which will be fed into our classifiers. For simplicity, we chose HOG as our feature. We also need to perform feature selection to avoid having more features than data points. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "hog_features = [hog(img) for img in X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(hog_features, y, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=14, \n",
    "                                                    shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up for PCA feature selection\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "pca = PCA(.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2916,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# No. of features before\n",
    "X_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCA(copy=True, iterated_power='auto', n_components=0.95, random_state=None,\n",
       "    svd_solver='auto', tol=0.0, whiten=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# No. of features after\n",
    "pca.n_components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pca.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Classification and Model selection\n",
    "\n",
    "No models are better than others in general so we will try different models and choose the best one according to our criteria which is accuracy. We will use three different models - SVM, Knn and random forest. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'SVC': GridSearchCV(SVC(), {\n",
    "        'kernel': ('linear', 'rbf', 'sigmoid'),\n",
    "        'C': [0.1, 1, 10]\n",
    "    }),\n",
    "    'KNN': GridSearchCV(KNeighborsClassifier(), {\n",
    "        'n_neighbors': [3,5,7,9],\n",
    "        'weights': ('uniform', 'distance')\n",
    "    }),\n",
    "    'RF': GridSearchCV(RandomForestClassifier(), {\n",
    "        'n_estimators': [50, 100, 200, 300, 500],\n",
    "    }),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in models.values():\n",
    "    model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC Accuracy 0.8125\n",
      "SVC Precision 1.0\n",
      "SVC Recall 0.5714285714285714\n",
      "KNN Accuracy 0.75\n",
      "KNN Precision 1.0\n",
      "KNN Recall 0.42857142857142855\n",
      "RF Accuracy 0.75\n",
      "RF Precision 0.7142857142857143\n",
      "RF Recall 0.7142857142857143\n"
     ]
    }
   ],
   "source": [
    "for name, model in models.items():\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(name, 'Accuracy', accuracy_score(y_test, y_pred))\n",
    "    print(name, 'Precision', precision_score(y_test, y_pred))\n",
    "    print(name, 'Recall', recall_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
